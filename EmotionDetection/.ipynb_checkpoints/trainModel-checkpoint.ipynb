{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b49049-9f19-4ab4-9de8-ea318efbcaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,InputLayer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Input\n",
    "from tensorflow.estimator import Estimator\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da5b005-c6dd-4ecd-be50-b0578135468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d8b432-ecdd-4182-9dd3-c27dd4553eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, 'completed')\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397a5bbd-9394-4dcb-ba9e-2ccc02bf1700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgusted completed\n",
      "fearful completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprised completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame();\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76067f12-d70a-456f-ae1d-9a5d52e242eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgusted completed\n",
      "fearful completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprised completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame();\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e11c7a1-ccf4-4558-b3b9-9892cac5ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}  \n",
    "    features = []\n",
    "\n",
    "    for image_path in tqdm(images):\n",
    "        image_path = os.path.normpath(image_path)\n",
    "\n",
    "        # Skip non-image files\n",
    "        if not os.path.splitext(image_path)[1].lower() in valid_extensions:\n",
    "            print(f\"Skipping non-image file: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = load_img(image_path, color_mode='grayscale', target_size=(48, 48))\n",
    "            img = np.array(img)\n",
    "            features.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80137a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       images/train\\angry\\im0.png\n",
      "1       images/train\\angry\\im1.png\n",
      "2      images/train\\angry\\im10.png\n",
      "3     images/train\\angry\\im100.png\n",
      "4    images/train\\angry\\im1000.png\n",
      "Name: image, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train['image'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "61697c90-ff0f-4f4b-be5d-51ce9fc5a54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2247d83e56d34bea8685511cf7962984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "62ce57df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985b382aaf8d4702a08427554624541e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c56834b-ae57-44ac-9baf-cf119b36fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919ded6d-e1af-48a0-afb6-9e4e3b812b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff83780-7b25-42dc-bce8-a6d916aa0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501d81b8-dd00-474c-a49a-e0b72a78355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191cb4ed-5df8-442e-a538-7c5fece19343",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44d26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384180c0-6f14-4a4d-8455-7c0cb859b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62446a2-b4e1-4422-96c4-067dfa209442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(48, 48, 1)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e1135-f679-44a2-a104-996eb5160321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c0f01-09f7-4e25-8023-710d86446c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 2235s 78ms/step - loss: 2.1758 - accuracy: 0.2313 - val_loss: 1.8188 - val_accuracy: 0.2471\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 17s 579us/step - loss: 1.8188 - accuracy: 0.2492 - val_loss: 1.8146 - val_accuracy: 0.2471\n",
      "Epoch 3/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8144 - accuracy: 0.2505 - val_loss: 1.8152 - val_accuracy: 0.2471\n",
      "Epoch 4/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8126 - accuracy: 0.2512 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 5/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8115 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 6/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8115 - accuracy: 0.2513 - val_loss: 1.8137 - val_accuracy: 0.2471\n",
      "Epoch 7/100\n",
      "28709/28709 [==============================] - 17s 588us/step - loss: 1.8117 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 8/100\n",
      "28709/28709 [==============================] - 16s 574us/step - loss: 1.8116 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 9/100\n",
      "28709/28709 [==============================] - 17s 576us/step - loss: 1.8118 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 10/100\n",
      "28709/28709 [==============================] - 18s 628us/step - loss: 1.8114 - accuracy: 0.2513 - val_loss: 1.8137 - val_accuracy: 0.2471\n",
      "Epoch 11/100\n",
      "28709/28709 [==============================] - 23s 798us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n",
      "Epoch 12/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 1.8113 - accuracy: 0.2513 - val_loss: 1.8142 - val_accuracy: 0.2471\n",
      "Epoch 13/100\n",
      "28709/28709 [==============================] - 18s 622us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 14/100\n",
      "28709/28709 [==============================] - 16s 572us/step - loss: 1.8110 - accuracy: 0.2513 - val_loss: 1.8167 - val_accuracy: 0.2471\n",
      "Epoch 15/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8112 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 16/100\n",
      "28709/28709 [==============================] - 18s 641us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 17/100\n",
      "28709/28709 [==============================] - 17s 609us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n",
      "Epoch 18/100\n",
      "28709/28709 [==============================] - 18s 639us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8142 - val_accuracy: 0.2471\n",
      "Epoch 19/100\n",
      "28709/28709 [==============================] - 18s 624us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 20/100\n",
      "28709/28709 [==============================] - 18s 621us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8145 - val_accuracy: 0.2471\n",
      "Epoch 21/100\n",
      "28709/28709 [==============================] - 18s 624us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 22/100\n",
      "28709/28709 [==============================] - 18s 617us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8130 - val_accuracy: 0.2471\n",
      "Epoch 23/100\n",
      "28709/28709 [==============================] - 18s 638us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 24/100\n",
      "28709/28709 [==============================] - 18s 639us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8087 - val_accuracy: 0.2471\n",
      "Epoch 25/100\n",
      "28709/28709 [==============================] - 18s 628us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 26/100\n",
      "28709/28709 [==============================] - 18s 637us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 27/100\n",
      "28709/28709 [==============================] - 18s 618us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 28/100\n",
      "28709/28709 [==============================] - 18s 624us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 29/100\n",
      "28709/28709 [==============================] - 18s 619us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8306 - val_accuracy: 0.2471\n",
      "Epoch 30/100\n",
      "28709/28709 [==============================] - 18s 634us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8137 - val_accuracy: 0.2471\n",
      "Epoch 31/100\n",
      "28709/28709 [==============================] - 18s 626us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 32/100\n",
      "28709/28709 [==============================] - 18s 616us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 33/100\n",
      "28709/28709 [==============================] - 18s 622us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 34/100\n",
      "28709/28709 [==============================] - 18s 616us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 35/100\n",
      "28709/28709 [==============================] - 18s 615us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8147 - val_accuracy: 0.2471\n",
      "Epoch 36/100\n",
      "28709/28709 [==============================] - 18s 617us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 37/100\n",
      "28709/28709 [==============================] - 19s 667us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 38/100\n",
      "28709/28709 [==============================] - 18s 624us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 39/100\n",
      "28709/28709 [==============================] - 18s 621us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 40/100\n",
      "28709/28709 [==============================] - 18s 629us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8144 - val_accuracy: 0.2471\n",
      "Epoch 41/100\n",
      "28709/28709 [==============================] - 18s 618us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8141 - val_accuracy: 0.2471\n",
      "Epoch 42/100\n",
      "28709/28709 [==============================] - 18s 641us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8141 - val_accuracy: 0.2471\n",
      "Epoch 43/100\n",
      "28709/28709 [==============================] - 19s 664us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8142 - val_accuracy: 0.2471\n",
      "Epoch 44/100\n",
      "28709/28709 [==============================] - 19s 653us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8144 - val_accuracy: 0.2471\n",
      "Epoch 45/100\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n",
      "Epoch 46/100\n",
      "28709/28709 [==============================] - 17s 598us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8141 - val_accuracy: 0.2471\n",
      "Epoch 47/100\n",
      "28709/28709 [==============================] - 18s 610us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n",
      "Epoch 48/100\n",
      "28709/28709 [==============================] - 21s 729us/step - loss: 1.8100 - accuracy: 0.2513 - val_loss: 1.8244 - val_accuracy: 0.2471\n",
      "Epoch 49/100\n",
      "28709/28709 [==============================] - 18s 626us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8193 - val_accuracy: 0.2471\n",
      "Epoch 50/100\n",
      "28709/28709 [==============================] - 18s 639us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 51/100\n",
      "28709/28709 [==============================] - 17s 602us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8143 - val_accuracy: 0.2471\n",
      "Epoch 52/100\n",
      "28709/28709 [==============================] - 18s 637us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8141 - val_accuracy: 0.2471\n",
      "Epoch 53/100\n",
      "28709/28709 [==============================] - 18s 633us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8142 - val_accuracy: 0.2471\n",
      "Epoch 54/100\n",
      "28709/28709 [==============================] - 19s 647us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "28709/28709 [==============================] - 17s 609us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8211 - val_accuracy: 0.2471\n",
      "Epoch 56/100\n",
      "28709/28709 [==============================] - 17s 591us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8140 - val_accuracy: 0.2471\n",
      "Epoch 57/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8140 - val_accuracy: 0.2471\n",
      "Epoch 58/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8144 - val_accuracy: 0.2471\n",
      "Epoch 59/100\n",
      "12800/28709 [============>.................] - ETA: 8s - loss: 1.8118 - accuracy: 0.2506"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7c74c73-eaa5-448c-b5a6-1c8348e4837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Emotiondetector.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"Emotiondetector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e494ac-8dbc-4bb7-bce2-1c9b3c07bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8445dfde-0e99-4054-9934-854c3960cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d3cb36-c323-41d7-8e1d-68a182683146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,color_mode = 'grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21b4b932-bd48-495c-9d33-2779f21f9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3677957a-57fb-4c5a-bb28-b8f9a94f48d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of happy\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17788cb1c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/happy/im0.png'\n",
    "print(\"Original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f085f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
