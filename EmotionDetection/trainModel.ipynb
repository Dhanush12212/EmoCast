{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b49049-9f19-4ab4-9de8-ea318efbcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da5b005-c6dd-4ecd-be50-b0578135468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d8b432-ecdd-4182-9dd3-c27dd4553eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, 'completed')\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397a5bbd-9394-4dcb-ba9e-2ccc02bf1700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame();\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1185fb55-3dff-45b3-a086-ebcaf21075e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76067f12-d70a-456f-ae1d-9a5d52e242eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame();\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda942ea-2dc5-4f8c-bc78-961c7cd33b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11c7a1-ccf4-4558-b3b9-9892cac5ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode='grayscale')\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61697c90-ff0f-4f4b-be5d-51ce9fc5a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671b23c442e4455ab29fdc0aafd8c600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c56834b-ae57-44ac-9baf-cf119b36fa20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m np.save(\u001b[33m'\u001b[39m\u001b[33mtrain_features.npy\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mtrain_features\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ded6d-e1af-48a0-afb6-9e4e3b812b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff83780-7b25-42dc-bce8-a6d916aa0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501d81b8-dd00-474c-a49a-e0b72a78355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "191cb4ed-5df8-442e-a538-7c5fece19343",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384180c0-6f14-4a4d-8455-7c0cb859b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62446a2-b4e1-4422-96c4-067dfa209442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(48, 48, 1)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b3e1135-f679-44a2-a104-996eb5160321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b27c0f01-09f7-4e25-8023-710d86446c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  6/226\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:13\u001b[0m 1s/step - accuracy: 0.2337 - loss: 1.8336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c74c73-eaa5-448c-b5a6-1c8348e4837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Emotiondetector.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"Emotiondetector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e494ac-8dbc-4bb7-bce2-1c9b3c07bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445dfde-0e99-4054-9934-854c3960cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neautral','sad','suprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d3cb36-c323-41d7-8e1d-68a182683146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,color_mode = 'grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21b4b932-bd48-495c-9d33-2779f21f9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3677957a-57fb-4c5a-bb28-b8f9a94f48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of fear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ac0bafc500>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/fear/2.jpg'\n",
    "print(\"Original image is of fear\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e315164e-5c79-47a6-9d9d-2f5dd43d700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of happy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ef' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m image = \u001b[33m'\u001b[39m\u001b[33mimages/train/happy/7.jpg\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal image is of happy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m img = \u001b[43mef\u001b[49m(image)\n\u001b[32m      4\u001b[39m pred = model.predict(img)\n\u001b[32m      5\u001b[39m pred_label = label[pred.argmax()]\n",
      "\u001b[31mNameError\u001b[39m: name 'ef' is not defined"
     ]
    }
   ],
   "source": [
    "image = 'images/train/happy/7.jpg'\n",
    "print(\"Original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5eac63-ac53-4a28-8d80-9b548bab121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 3993, 'disgust': 436, 'fear': 4103, 'happy': 7164, 'neutral': 4982, 'sad': 4938, 'surprise': 3205}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "data_path = 'images/train'\n",
    "class_counts = {cls: len(os.listdir(os.path.join(data_path, cls))) for cls in os.listdir(data_path)}\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8003dd76-4b56-4dec-94a4-f944842caf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02699c39-c382-4fcc-a725-ddac3ef50d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _MklMatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor([[11.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Example computation\n",
    "a = tf.constant([[1.0, 2.0]])\n",
    "b = tf.constant([[3.0], [4.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a5e47-a74a-4c44-a2ed-76004860a60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458d3ad-29a0-4fbe-9d2c-bad5b20f8fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
