{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b49049-9f19-4ab4-9de8-ea318efbcaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,InputLayer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Input\n",
    "from tensorflow.estimator import Estimator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'\n",
    "\n",
    "\n",
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, 'completed')\n",
    "    return image_paths,labels\n",
    "\n",
    "\n",
    "train = pd.DataFrame();\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "\n",
    "\n",
    "test = pd.DataFrame();\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
    "\n",
    "\n",
    "def extract_features(images):\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}  \n",
    "    features = []\n",
    "\n",
    "    for image_path in tqdm(images):\n",
    "        image_path = os.path.normpath(image_path)\n",
    "\n",
    "        # Skip non-image files\n",
    "        if not os.path.splitext(image_path)[1].lower() in valid_extensions:\n",
    "            print(f\"Skipping non-image file: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = load_img(image_path, color_mode='grayscale', target_size=(48, 48))\n",
    "            img = np.array(img)\n",
    "            features.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n",
    "\n",
    "\n",
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy')\n",
    "\n",
    "\n",
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0\n",
    "\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "\n",
    "\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "\n",
    "\n",
    "# convolutional layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(48, 48, 1)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "\n",
    "def ef(image):\n",
    "    img = load_img(image,color_mode = 'grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c56834b-ae57-44ac-9baf-cf119b36fa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b55efd67e4260b38ab0e8337e36e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3672f2f28b41ec84a6ef50e0c4d62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "test_features  = extract_features(test['image'])\n",
    "\n",
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc5cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (28709, 48, 48, 1)\n",
      "y_train shape: (28709, 7)\n",
      "x_test shape: (7178, 48, 48, 1)\n",
      "y_test shape: (7178, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b3e1135-f679-44a2-a104-996eb5160321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b27c0f01-09f7-4e25-8023-710d86446c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 17s 587us/step - loss: 1.9342 - accuracy: 0.2321 - val_loss: 2.5157 - val_accuracy: 0.2471\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8192 - accuracy: 0.2481 - val_loss: 1.8895 - val_accuracy: 0.2471\n",
      "Epoch 3/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8139 - accuracy: 0.2504 - val_loss: 1.8223 - val_accuracy: 0.2471 0.25\n",
      "Epoch 4/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8125 - accuracy: 0.2510 - val_loss: 1.8074 - val_accuracy: 0.2471\n",
      "Epoch 5/100\n",
      "28709/28709 [==============================] - 17s 590us/step - loss: 1.8121 - accuracy: 0.2510 - val_loss: 1.8222 - val_accuracy: 0.2471\n",
      "Epoch 6/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8125 - accuracy: 0.2509 - val_loss: 1.8481 - val_accuracy: 0.2471\n",
      "Epoch 7/100\n",
      "28709/28709 [==============================] - 16s 570us/step - loss: 1.8114 - accuracy: 0.2513 - val_loss: 1.8378 - val_accuracy: 0.2471\n",
      "Epoch 8/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8113 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 9/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8123 - accuracy: 0.2509 - val_loss: 1.8137 - val_accuracy: 0.2471\n",
      "Epoch 10/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8140 - accuracy: 0.2511 - val_loss: 1.8414 - val_accuracy: 0.2471\n",
      "Epoch 11/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8109 - accuracy: 0.2512 - val_loss: 1.8262 - val_accuracy: 0.2471\n",
      "Epoch 12/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8113 - accuracy: 0.2512 - val_loss: 1.8283 - val_accuracy: 0.2471\n",
      "Epoch 13/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8165 - accuracy: 0.2510 - val_loss: 1.8129 - val_accuracy: 0.2471\n",
      "Epoch 14/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8147 - accuracy: 0.2502 - val_loss: 1.8193 - val_accuracy: 0.2471\n",
      "Epoch 15/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8120 - accuracy: 0.2507 - val_loss: 1.8110 - val_accuracy: 0.2471\n",
      "Epoch 16/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8109 - accuracy: 0.2514 - val_loss: 1.8264 - val_accuracy: 0.2471\n",
      "Epoch 17/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8176 - accuracy: 0.2511 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 18/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8112 - accuracy: 0.2513 - val_loss: 1.8198 - val_accuracy: 0.2471\n",
      "Epoch 19/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8123 - accuracy: 0.2511 - val_loss: 1.8187 - val_accuracy: 0.2471\n",
      "Epoch 20/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8116 - accuracy: 0.2509 - val_loss: 1.8178 - val_accuracy: 0.2471\n",
      "Epoch 21/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8032 - val_accuracy: 0.2471\n",
      "Epoch 22/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8069 - val_accuracy: 0.2471\n",
      "Epoch 23/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 24/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8113 - accuracy: 0.2510 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 25/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8152 - accuracy: 0.2500 - val_loss: 1.8083 - val_accuracy: 0.2471\n",
      "Epoch 26/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8234 - accuracy: 0.2509 - val_loss: 1.8122 - val_accuracy: 0.2471\n",
      "Epoch 27/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.7784 - val_accuracy: 0.2471\n",
      "Epoch 28/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8139 - val_accuracy: 0.2471\n",
      "Epoch 29/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8108 - accuracy: 0.2511 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 30/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8113 - accuracy: 0.2510 - val_loss: 1.7956 - val_accuracy: 0.2471\n",
      "Epoch 31/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8107 - accuracy: 0.2512 - val_loss: 1.8122 - val_accuracy: 0.2471\n",
      "Epoch 32/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8284 - val_accuracy: 0.2471\n",
      "Epoch 33/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8118 - accuracy: 0.2511 - val_loss: 1.8141 - val_accuracy: 0.2471\n",
      "Epoch 34/100\n",
      "28709/28709 [==============================] - 16s 575us/step - loss: 1.8119 - accuracy: 0.2510 - val_loss: 1.7683 - val_accuracy: 0.3468\n",
      "Epoch 35/100\n",
      "28709/28709 [==============================] - 16s 572us/step - loss: 1.8110 - accuracy: 0.2508 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 36/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 37/100\n",
      "28709/28709 [==============================] - 17s 575us/step - loss: 1.8105 - accuracy: 0.2512 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 38/100\n",
      "28709/28709 [==============================] - 17s 577us/step - loss: 1.8149 - accuracy: 0.2500 - val_loss: 1.8137 - val_accuracy: 0.2471\n",
      "Epoch 39/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8120 - accuracy: 0.2509 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 40/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 41/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8140 - accuracy: 0.2512 - val_loss: 1.8439 - val_accuracy: 0.3150\n",
      "Epoch 42/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8133 - accuracy: 0.2511 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 43/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 44/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 45/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8733 - accuracy: 0.2493 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 46/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8223 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 47/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8117 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 48/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8151 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 49/100\n",
      "28709/28709 [==============================] - 16s 562us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 50/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8130 - val_accuracy: 0.2471\n",
      "Epoch 51/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 52/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 53/100\n",
      "28709/28709 [==============================] - 16s 561us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 54/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8105 - val_accuracy: 0.2471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "28709/28709 [==============================] - 16s 560us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 56/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 57/100\n",
      "28709/28709 [==============================] - 531s 18ms/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 58/100\n",
      "28709/28709 [==============================] - 16s 574us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 59/100\n",
      "28709/28709 [==============================] - 16s 552us/step - loss: 1.8182 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 60/100\n",
      "28709/28709 [==============================] - 16s 553us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 61/100\n",
      "28709/28709 [==============================] - 16s 563us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8136 - val_accuracy: 0.2471\n",
      "Epoch 62/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 63/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 64/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 65/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 66/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8229 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 67/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8100 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2471\n",
      "Epoch 68/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 69/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 70/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 71/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8181 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 72/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8130 - val_accuracy: 0.2471\n",
      "Epoch 73/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 74/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 75/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 76/100\n",
      "28709/28709 [==============================] - 16s 572us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 77/100\n",
      "28709/28709 [==============================] - 16s 570us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 78/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 79/100\n",
      "28709/28709 [==============================] - 16s 564us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 80/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 81/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 2.0913 - val_accuracy: 0.1737\n",
      "Epoch 82/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 83/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8226 - val_accuracy: 0.24711.8097 \n",
      "Epoch 84/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 85/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8130 - val_accuracy: 0.2471\n",
      "Epoch 86/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 87/100\n",
      "28709/28709 [==============================] - 16s 565us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2471\n",
      "Epoch 88/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 89/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 90/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 91/100\n",
      "28709/28709 [==============================] - 16s 571us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 92/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 93/100\n",
      "28709/28709 [==============================] - 16s 568us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2471\n",
      "Epoch 94/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 95/100\n",
      "28709/28709 [==============================] - 16s 566us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8131 - val_accuracy: 0.2471\n",
      "Epoch 96/100\n",
      "28709/28709 [==============================] - 16s 569us/step - loss: 1.8101 - accuracy: 0.2513 - val_loss: 1.8130 - val_accuracy: 0.2471\n",
      "Epoch 97/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2471\n",
      "Epoch 98/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8133 - val_accuracy: 0.2471\n",
      "Epoch 99/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.7730 - val_accuracy: 0.2471\n",
      "Epoch 100/100\n",
      "28709/28709 [==============================] - 16s 567us/step - loss: 2.6279 - accuracy: 0.2510 - val_loss: 1.7724 - val_accuracy: 0.2225\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train, y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7c74c73-eaa5-448c-b5a6-1c8348e4837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Emotiondetector.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"Emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be7219ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of angry\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc85ad97b8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "image = 'images/train/angry/im3.png'\n",
    "print(\"original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab46091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 24.71%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1223c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.714405126776263 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)   # predicted labels\n",
    "y_true = np.argmax(y_test, axis=1)           # actual labels\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred_classes) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919efcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
